{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11163296,"sourceType":"datasetVersion","datasetId":6924352},{"sourceId":11189284,"sourceType":"datasetVersion","datasetId":6984989}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mức 2: Đánh giá mô hình deraining (pretrained) trên dữ liệu ngoài bài báo\n**CHÚ Ý:**\n- Bật GPU T4 x2 trước khi chạy notebook\n- Thêm các Kaggle dataset sau làm input:\n    - For pre-trained weight: https://kaggle.com/datasets/48e9d5bc84d59d1aaee28d770c6ceae05bcbc151efe901d644ab2a354afae48b\n    - For test set: https://kaggle.com/datasets/5400c159acc0837a0cbf3834149bc5e03004a42c8bc22245927af84233815c56","metadata":{}},{"cell_type":"markdown","source":"# Môi trường & Dependencies\n- Kaggle","metadata":{}},{"cell_type":"code","source":"!cat /etc/*release","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-27T20:04:53.750222Z","iopub.execute_input":"2025-03-27T20:04:53.750588Z","iopub.status.idle":"2025-03-27T20:04:53.880236Z","shell.execute_reply.started":"2025-03-27T20:04:53.750534Z","shell.execute_reply":"2025-03-27T20:04:53.879297Z"},"trusted":true},"outputs":[{"name":"stdout","text":"DISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=22.04\nDISTRIB_CODENAME=jammy\nDISTRIB_DESCRIPTION=\"Ubuntu 22.04.3 LTS\"\nPRETTY_NAME=\"Ubuntu 22.04.3 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"22.04\"\nVERSION=\"22.04.3 LTS (Jammy Jellyfish)\"\nVERSION_CODENAME=jammy\nID=ubuntu\nID_LIKE=debian\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nUBUNTU_CODENAME=jammy\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:04:53.881353Z","iopub.execute_input":"2025-03-27T20:04:53.881657Z","iopub.status.idle":"2025-03-27T20:04:53.885553Z","shell.execute_reply.started":"2025-03-27T20:04:53.881634Z","shell.execute_reply":"2025-03-27T20:04:53.884817Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# !sudo apt-get install libtinfo5","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:04:53.886550Z","iopub.execute_input":"2025-03-27T20:04:53.886897Z","iopub.status.idle":"2025-03-27T20:04:53.901993Z","shell.execute_reply.started":"2025-03-27T20:04:53.886863Z","shell.execute_reply":"2025-03-27T20:04:53.901172Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!python --version\n!python3.8 --version","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:04:53.903047Z","iopub.execute_input":"2025-03-27T20:04:53.903355Z","iopub.status.idle":"2025-03-27T20:04:54.155929Z","shell.execute_reply.started":"2025-03-27T20:04:53.903317Z","shell.execute_reply":"2025-03-27T20:04:54.154864Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Python 3.10.12\n/bin/bash: line 1: python3.8: command not found\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# !sudo apt update\n# !sudo apt install python3.8 python3.8-distutils\n# !sudo apt install python3.8-dev","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:04:54.157009Z","iopub.execute_input":"2025-03-27T20:04:54.157343Z","iopub.status.idle":"2025-03-27T20:04:54.161294Z","shell.execute_reply.started":"2025-03-27T20:04:54.157304Z","shell.execute_reply":"2025-03-27T20:04:54.160313Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!python --version\n!python3.8 --version","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:04:54.163833Z","iopub.execute_input":"2025-03-27T20:04:54.164057Z","iopub.status.idle":"2025-03-27T20:04:54.408994Z","shell.execute_reply.started":"2025-03-27T20:04:54.164038Z","shell.execute_reply":"2025-03-27T20:04:54.408015Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Python 3.10.12\n/bin/bash: line 1: python3.8: command not found\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# %cd /kaggle\n# !wget https://bootstrap.pypa.io/get-pip.py\n# !sudo python3.8 get-pip.py","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:04:54.410873Z","iopub.execute_input":"2025-03-27T20:04:54.411138Z","iopub.status.idle":"2025-03-27T20:04:54.414606Z","shell.execute_reply.started":"2025-03-27T20:04:54.411116Z","shell.execute_reply":"2025-03-27T20:04:54.413868Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip --version\n!pip3.8 --version","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:04:54.415563Z","iopub.execute_input":"2025-03-27T20:04:54.415835Z","iopub.status.idle":"2025-03-27T20:04:55.253965Z","shell.execute_reply.started":"2025-03-27T20:04:54.415801Z","shell.execute_reply":"2025-03-27T20:04:55.252772Z"},"trusted":true},"outputs":[{"name":"stdout","text":"pip 24.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n/bin/bash: line 1: pip3.8: command not found\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# !python3.8 -m pip install torch==1.8.1 torchvision==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:04:55.255236Z","iopub.execute_input":"2025-03-27T20:04:55.255644Z","iopub.status.idle":"2025-03-27T20:04:55.259920Z","shell.execute_reply.started":"2025-03-27T20:04:55.255609Z","shell.execute_reply":"2025-03-27T20:04:55.259115Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"!pip show torch torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:04:55.260747Z","iopub.execute_input":"2025-03-27T20:04:55.260993Z","iopub.status.idle":"2025-03-27T20:05:00.983618Z","shell.execute_reply.started":"2025-03-27T20:04:55.260964Z","shell.execute_reply":"2025-03-27T20:05:00.982456Z"}},"outputs":[{"name":"stdout","text":"Name: torch\nVersion: 2.5.1+cu121\nSummary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\nHome-page: https://pytorch.org/\nAuthor: PyTorch Team\nAuthor-email: packages@pytorch.org\nLicense: BSD-3-Clause\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\nRequired-by: accelerate, easyocr, fastai, kornia, peft, pytorch-ignite, pytorch-lightning, sentence-transformers, stable-baselines3, timm, torchaudio, torchmetrics, torchvision\n---\nName: torchvision\nVersion: 0.20.1+cu121\nSummary: image and video datasets and models for torch deep learning\nHome-page: https://github.com/pytorch/vision\nAuthor: PyTorch Core Team\nAuthor-email: soumith@pytorch.org\nLicense: BSD\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: numpy, pillow, torch\nRequired-by: easyocr, fastai, timm\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# !pip3.8 install tensorboard einops scikit-image pytorch_msssim opencv-python\n!pip install tensorboard einops scikit-image pytorch_msssim opencv-python","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:00.984905Z","iopub.execute_input":"2025-03-27T20:05:00.985168Z","iopub.status.idle":"2025-03-27T20:05:05.790752Z","shell.execute_reply.started":"2025-03-27T20:05:00.985146Z","shell.execute_reply":"2025-03-27T20:05:05.789727Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.25.0)\nCollecting pytorch_msssim\n  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\nRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\nRequirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (11.0.0)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.12.12)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_msssim) (2.5.1+cu121)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (4.12.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pytorch_msssim) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\nInstalling collected packages: pytorch_msssim\nSuccessfully installed pytorch_msssim-1.0.0\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip show tensorboard einops scikit-image pytorch_msssim opencv-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:05:05.791784Z","iopub.execute_input":"2025-03-27T20:05:05.792081Z","iopub.status.idle":"2025-03-27T20:05:09.148199Z","shell.execute_reply.started":"2025-03-27T20:05:05.792057Z","shell.execute_reply":"2025-03-27T20:05:09.147167Z"}},"outputs":[{"name":"stdout","text":"Name: tensorboard\nVersion: 2.17.1\nSummary: TensorBoard lets you watch Tensors Flow\nHome-page: https://github.com/tensorflow/tensorboard\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: absl-py, grpcio, markdown, numpy, packaging, protobuf, setuptools, six, tensorboard-data-server, werkzeug\nRequired-by: tensorflow\n---\nName: einops\nVersion: 0.8.0\nSummary: A new flavour of deep learning operations\nHome-page: https://github.com/arogozhnikov/einops\nAuthor: Alex Rogozhnikov\nAuthor-email: \nLicense: MIT\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: \nRequired-by: \n---\nName: scikit-image\nVersion: 0.25.0\nSummary: Image processing in Python\nHome-page: https://scikit-image.org\nAuthor: \nAuthor-email: \nLicense: Files: *\n         Copyright: 2009-2022 the scikit-image team\n         License: BSD-3-Clause\n         \n         Files: doc/source/themes/scikit-image/layout.html\n         Copyright: 2007-2010 the Sphinx team\n         License: BSD-3-Clause\n         \n         Files: skimage/feature/_canny.py\n                skimage/filters/edges.py\n                skimage/filters/_rank_order.py\n                skimage/morphology/_skeletonize.py\n                skimage/morphology/tests/test_watershed.py\n                skimage/morphology/watershed.py\n                skimage/segmentation/heap_general.pxi\n                skimage/segmentation/heap_watershed.pxi\n                skimage/segmentation/_watershed.py\n                skimage/segmentation/_watershed_cy.pyx\n         Copyright: 2003-2009 Massachusetts Institute of Technology\n                    2009-2011 Broad Institute\n                    2003 Lee Kamentsky\n                    2003-2005 Peter J. Verveer\n         License: BSD-3-Clause\n         \n         Files: skimage/filters/thresholding.py\n                skimage/graph/_mcp.pyx\n                skimage/graph/heap.pyx\n         Copyright: 2009-2015 Board of Regents of the University of\n                    Wisconsin-Madison, Broad Institute of MIT and Harvard,\n                    and Max Planck Institute of Molecular Cell Biology and\n                    Genetics\n                    2009 Zachary Pincus\n                    2009 Almar Klein\n         License: BSD-2-Clause\n         \n         File: skimage/morphology/grayreconstruct.py\n               skimage/morphology/tests/test_reconstruction.py\n         Copyright: 2003-2009 Massachusetts Institute of Technology\n                    2009-2011 Broad Institute\n                    2003 Lee Kamentsky\n         License: BSD-3-Clause\n         \n         File: skimage/morphology/_grayreconstruct.pyx\n         Copyright: 2003-2009 Massachusetts Institute of Technology\n                    2009-2011 Broad Institute\n                    2003 Lee Kamentsky\n                    2022 Gregory Lee (added a 64-bit integer variant for large images)\n         License: BSD-3-Clause\n         \n         File: skimage/segmentation/_expand_labels.py\n         Copyright: 2020 Broad Institute\n                    2020 CellProfiler team\n         License: BSD-3-Clause\n         \n         File: skimage/exposure/_adapthist.py\n         Copyright: 1994 Karel Zuiderveld\n         License: BSD-3-Clause\n         \n         Function: skimage/morphology/_skeletonize_various_cy.pyx:_skeletonize_loop\n         Copyright: 2003-2009 Massachusetts Institute of Technology\n                    2009-2011 Broad Institute\n                    2003 Lee Kamentsky\n         License: BSD-3-Clause\n         \n         Function: skimage/_shared/version_requirements.py:_check_version\n         Copyright: 2013 The IPython Development Team\n         License: BSD-3-Clause\n         \n         Function: skimage/_shared/version_requirements.py:is_installed\n         Copyright: 2009-2011 Pierre Raybaut\n         License: MIT\n         \n         File: skimage/feature/_fisher_vector.py\n         Copyright: 2014 2014 Dan Oneata\n         License: MIT\n         \n         File: skimage/_vendored/numpy_lookfor.py\n         Copyright: 2005-2023, NumPy Developers\n         License: BSD-3-Clause\n         \n         File: skimage/transform/_thin_plate_splines.py\n         Copyright: 2007 Zachary Pincus\n         License: BSD-3-Clause\n         \n         License: BSD-2-Clause\n         \n         Redistribution and use in source and binary forms, with or without\n         modification, are permitted provided that the following conditions\n         are met:\n         1. Redistributions of source code must retain the above copyright\n            notice, this list of conditions and the following disclaimer.\n         2. Redistributions in binary form must reproduce the above copyright\n            notice, this list of conditions and the following disclaimer in the\n            documentation and/or other materials provided with the distribution.\n         .\n         THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n         ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n         LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n         A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE HOLDERS OR\n         CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n         EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n         PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n         PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n         LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n         NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n         SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n         \n         License: BSD-3-Clause\n         \n         Redistribution and use in source and binary forms, with or without\n         modification, are permitted provided that the following conditions\n         are met:\n         1. Redistributions of source code must retain the above copyright\n            notice, this list of conditions and the following disclaimer.\n         2. Redistributions in binary form must reproduce the above copyright\n            notice, this list of conditions and the following disclaimer in the\n            documentation and/or other materials provided with the distribution.\n         3. Neither the name of the University nor the names of its contributors\n            may be used to endorse or promote products derived from this software\n            without specific prior written permission.\n         .\n         THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n         ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n         LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n         A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE HOLDERS OR\n         CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n         EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n         PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n         PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n         LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n         NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n         SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n         \n         License: MIT\n         \n         Permission is hereby granted, free of charge, to any person obtaining a copy\n         of this software and associated documentation files (the \"Software\"), to deal\n         in the Software without restriction, including without limitation the rights\n         to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n         copies of the Software, and to permit persons to whom the Software is\n         furnished to do so, subject to the following conditions:\n         \n         The above copyright notice and this permission notice shall be included in all\n         copies or substantial portions of the Software.\n         \n         THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n         IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n         FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n         AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n         LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n         OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n         SOFTWARE.\n         \nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: imageio, lazy-loader, networkx, numpy, packaging, pillow, scipy, tifffile\nRequired-by: easyocr, imgaug, lime\n---\nName: pytorch-msssim\nVersion: 1.0.0\nSummary: Fast and differentiable MS-SSIM and SSIM for pytorch.\nHome-page: https://github.com/VainF/pytorch-msssim\nAuthor: Gongfan Fang\nAuthor-email: gongfan@u.nus.edu\nLicense: \nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: torch\nRequired-by: \n---\nName: opencv-python\nVersion: 4.10.0.84\nSummary: Wrapper package for OpenCV python bindings.\nHome-page: https://github.com/opencv/opencv-python\nAuthor: \nAuthor-email: \nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: numpy\nRequired-by: dopamine_rl, imgaug\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Copy source code","metadata":{}},{"cell_type":"code","source":"!cp -r \"/kaggle/input/sfnet-source-code-and-model/SFNet\" \\\n    \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:09.149462Z","iopub.execute_input":"2025-03-27T20:05:09.149864Z","iopub.status.idle":"2025-03-27T20:05:09.804334Z","shell.execute_reply.started":"2025-03-27T20:05:09.149825Z","shell.execute_reply":"2025-03-27T20:05:09.803318Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"!cp \"/kaggle/input/youtube-frames-for-deraining/test_derain_youtube.py\" \\\n    \"/kaggle/working/SFNet/Image_deraining/\"","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:09.805311Z","iopub.execute_input":"2025-03-27T20:05:09.805566Z","iopub.status.idle":"2025-03-27T20:05:09.934358Z","shell.execute_reply.started":"2025-03-27T20:05:09.805543Z","shell.execute_reply":"2025-03-27T20:05:09.933307Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:09.935408Z","iopub.execute_input":"2025-03-27T20:05:09.935677Z","iopub.status.idle":"2025-03-27T20:05:10.060361Z","shell.execute_reply.started":"2025-03-27T20:05:09.935653Z","shell.execute_reply":"2025-03-27T20:05:10.059356Z"},"trusted":true},"outputs":[{"name":"stdout","text":"SFNet\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Kiểm tra dữ liệu đã thêm vào Kaggle Input","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/sfnet-source-code-and-model","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:10.061672Z","iopub.execute_input":"2025-03-27T20:05:10.062049Z","iopub.status.idle":"2025-03-27T20:05:10.187518Z","shell.execute_reply.started":"2025-03-27T20:05:10.062012Z","shell.execute_reply":"2025-03-27T20:05:10.186540Z"},"trusted":true},"outputs":[{"name":"stdout","text":"deraining.pkl\t\t  fixed_main_for_deraining.py  test_derain_muc_2b.py\nderaining_runtime_weight  SFNet\t\t\t       test_derain_muc_2.py\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!ls /kaggle/input/youtube-frames-for-deraining","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:10.188614Z","iopub.execute_input":"2025-03-27T20:05:10.188877Z","iopub.status.idle":"2025-03-27T20:05:10.314895Z","shell.execute_reply.started":"2025-03-27T20:05:10.188855Z","shell.execute_reply":"2025-03-27T20:05:10.313942Z"},"trusted":true},"outputs":[{"name":"stdout","text":"extracted_from_videos  test_derain_youtube.py\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Copy dữ liệu từ Kaggle Input","metadata":{}},{"cell_type":"code","source":"!mkdir -p /kaggle/working/test_data/","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:10.315952Z","iopub.execute_input":"2025-03-27T20:05:10.316204Z","iopub.status.idle":"2025-03-27T20:05:10.435867Z","shell.execute_reply.started":"2025-03-27T20:05:10.316182Z","shell.execute_reply":"2025-03-27T20:05:10.434610Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!cp -r \"/kaggle/input/youtube-frames-for-deraining/extracted_from_videos/extracted_from_videos/\"* \\\n    \"/kaggle/working/test_data/\"","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:10.437174Z","iopub.execute_input":"2025-03-27T20:05:10.437565Z","iopub.status.idle":"2025-03-27T20:05:13.667736Z","shell.execute_reply.started":"2025-03-27T20:05:10.437522Z","shell.execute_reply":"2025-03-27T20:05:13.666584Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"!ls \"/kaggle/working/test_data/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:05:13.671759Z","iopub.execute_input":"2025-03-27T20:05:13.672045Z","iopub.status.idle":"2025-03-27T20:05:13.792816Z","shell.execute_reply.started":"2025-03-27T20:05:13.672021Z","shell.execute_reply":"2025-03-27T20:05:13.791559Z"}},"outputs":[{"name":"stdout","text":"video1\tvideo2\tvideo3\tvideo4\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Create temporary ground truth images\nimport os\n\ndata_dir = \"/kaggle/working/test_data/\"\ntest_sets = [\"video1\", \"video2\", \"video3\", \"video4\"]\n\nfor test_set in test_sets:\n    input_dir = os.path.join(data_dir, test_set, \"input\")\n    target_dir = os.path.join(data_dir, test_set, \"target\")\n\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    for filename in os.listdir(input_dir):\n        if filename.endswith(\".png\"):\n            # Create a temporary ground truth image\n            temp_gt_path = os.path.join(target_dir, filename)\n            \n            # Copy the input image to the target directory\n            input_path = os.path.join(input_dir, filename)\n            \n            os.system(f\"cp {input_path} {temp_gt_path}\")\n\n            print(f\"Created fake ground truth image: {temp_gt_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:13.794622Z","iopub.execute_input":"2025-03-27T20:05:13.794901Z","iopub.status.idle":"2025-03-27T20:05:14.202052Z","shell.execute_reply.started":"2025-03-27T20:05:13.794876Z","shell.execute_reply":"2025-03-27T20:05:14.200916Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Created fake ground truth image: /kaggle/working/test_data/video1/target/frame_15.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_16.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_3.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_13.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_20.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_9.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_1.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_17.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_2.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_14.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_4.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_19.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_18.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_12.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_6.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_11.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_10.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_5.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_8.png\nCreated fake ground truth image: /kaggle/working/test_data/video1/target/frame_7.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_15.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_16.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_3.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_13.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_20.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_9.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_1.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_17.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_2.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_14.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_4.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_19.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_18.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_12.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_6.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_11.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_10.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_5.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_8.png\nCreated fake ground truth image: /kaggle/working/test_data/video2/target/frame_7.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_15.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_16.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_3.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_13.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_20.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_9.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_1.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_17.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_2.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_14.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_4.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_19.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_18.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_12.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_6.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_11.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_10.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_5.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_8.png\nCreated fake ground truth image: /kaggle/working/test_data/video3/target/frame_7.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_15.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_16.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_3.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_13.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_20.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_9.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_1.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_17.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_2.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_14.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_4.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_19.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_18.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_12.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_6.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_11.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_10.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_5.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_8.png\nCreated fake ground truth image: /kaggle/working/test_data/video4/target/frame_7.png\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# # %cd /content/drive/MyDrive/advanced_machine_learning/colab/SFNet/Motion_deblurring\n# %cd /kaggle/SFNet\n# %cd pytorch-gradual-warmup-lr/\n# # !python3.8 setup.py install\n# !python setup.py install\n# # !python3.10 setup.py install\n# %cd ..","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:14.203296Z","iopub.execute_input":"2025-03-27T20:05:14.203729Z","iopub.status.idle":"2025-03-27T20:05:14.208038Z","shell.execute_reply.started":"2025-03-27T20:05:14.203691Z","shell.execute_reply":"2025-03-27T20:05:14.206869Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# !cp /kaggle/SFNet/Image_dehazing/eval.py /kaggle/SFNet/Image_deraining\n# !cp /kaggle/SFNet/Motion_deblurring/eval.py /kaggle/SFNet/Image_deraining","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:14.209067Z","iopub.execute_input":"2025-03-27T20:05:14.209318Z","iopub.status.idle":"2025-03-27T20:05:14.271585Z","shell.execute_reply.started":"2025-03-27T20:05:14.209296Z","shell.execute_reply":"2025-03-27T20:05:14.270578Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"!mkdir /kaggle/working/SFNet/Image_deraining/results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:05:14.272521Z","iopub.execute_input":"2025-03-27T20:05:14.272800Z","iopub.status.idle":"2025-03-27T20:05:14.404869Z","shell.execute_reply.started":"2025-03-27T20:05:14.272777Z","shell.execute_reply":"2025-03-27T20:05:14.403529Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"!mkdir -p /kaggle/working/paper_pretrained_weight_results/\n!mkdir -p /kaggle/working/our_fine_tuned_weight_results/","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:14.406150Z","iopub.execute_input":"2025-03-27T20:05:14.406496Z","iopub.status.idle":"2025-03-27T20:05:14.642542Z","shell.execute_reply.started":"2025-03-27T20:05:14.406461Z","shell.execute_reply":"2025-03-27T20:05:14.641244Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"%cd /kaggle/working/SFNet/Image_deraining\n%pwd\n%ls","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:14.643630Z","iopub.execute_input":"2025-03-27T20:05:14.643913Z","iopub.status.idle":"2025-03-27T20:05:14.769108Z","shell.execute_reply.started":"2025-03-27T20:05:14.643888Z","shell.execute_reply":"2025-03-27T20:05:14.767886Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/SFNet/Image_deraining\n\u001b[0m\u001b[01;34mdata\u001b[0m/             \u001b[01;34mmodels\u001b[0m/    test_derain_youtube.py  utils.py\nderaining_test.m  README.md  test.py                 valid.py\nmain.py           \u001b[01;34mresults\u001b[0m/   train.py\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"!python test_derain_youtube.py --test_model /kaggle/input/sfnet-source-code-and-model/deraining.pkl \\\n    --data_dir /kaggle/working/test_data/ ","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:05:14.770251Z","iopub.execute_input":"2025-03-27T20:05:14.770585Z","iopub.status.idle":"2025-03-27T20:08:21.715385Z","shell.execute_reply.started":"2025-03-27T20:05:14.770560Z","shell.execute_reply":"2025-03-27T20:08:21.714245Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/SFNet/Image_deraining/test_derain_youtube.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(args.test_model)\nresults/SFNet/deraining/video1\n100%|███████████████████████████████████████████| 20/20 [00:11<00:00,  1.75it/s]\n==========================================================\nresults/SFNet/deraining/video2\n100%|███████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]\n==========================================================\nresults/SFNet/deraining/video3\n100%|███████████████████████████████████████████| 20/20 [01:23<00:00,  4.19s/it]\n==========================================================\nresults/SFNet/deraining/video4\n100%|███████████████████████████████████████████| 20/20 [00:37<00:00,  1.85s/it]\n==========================================================\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!mv /kaggle/working/SFNet/Image_deraining/results /kaggle/working/paper_pretrained_weight_results/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:08:21.716830Z","iopub.execute_input":"2025-03-27T20:08:21.717190Z","iopub.status.idle":"2025-03-27T20:08:21.844911Z","shell.execute_reply.started":"2025-03-27T20:08:21.717157Z","shell.execute_reply":"2025-03-27T20:08:21.843560Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"!rm -rf /kaggle/working/SFNet/Image_deraining/results/*\n!mkdir /kaggle/working/SFNet/Image_deraining/results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:09:19.891227Z","iopub.execute_input":"2025-03-27T20:09:19.891641Z","iopub.status.idle":"2025-03-27T20:09:20.124276Z","shell.execute_reply.started":"2025-03-27T20:09:19.891608Z","shell.execute_reply":"2025-03-27T20:09:20.122867Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"!python test_derain_youtube.py --test_model /kaggle/input/sfnet-source-code-and-model/deraining_runtime_weight/model_420.pkl \\\n    --data_dir /kaggle/working/test_data/ ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:09:23.511788Z","iopub.execute_input":"2025-03-27T20:09:23.512134Z","iopub.status.idle":"2025-03-27T20:12:16.276048Z","shell.execute_reply.started":"2025-03-27T20:09:23.512109Z","shell.execute_reply":"2025-03-27T20:12:16.274900Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/SFNet/Image_deraining/test_derain_youtube.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(args.test_model)\nresults/SFNet/deraining/video1\n100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.03it/s]\n==========================================================\nresults/SFNet/deraining/video2\n100%|███████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]\n==========================================================\nresults/SFNet/deraining/video3\n100%|███████████████████████████████████████████| 20/20 [01:25<00:00,  4.29s/it]\n==========================================================\nresults/SFNet/deraining/video4\n100%|███████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]\n==========================================================\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"!mv /kaggle/working/SFNet/Image_deraining/results /kaggle/working/our_fine_tuned_weight_results/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:12:16.277357Z","iopub.execute_input":"2025-03-27T20:12:16.277650Z","iopub.status.idle":"2025-03-27T20:12:16.398061Z","shell.execute_reply.started":"2025-03-27T20:12:16.277625Z","shell.execute_reply":"2025-03-27T20:12:16.396727Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"# Download dữ liệu\n- Kết quả đã được upload tại link: https://studenthcmusedu-my.sharepoint.com/:u:/g/personal/24c11071_student_hcmus_edu_vn/EWSPaAJNn_VAhU-uE39hGvsBGCv1ttneuctYAZjejSkqxQ?e=aNiZdc","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:12:16.400308Z","iopub.execute_input":"2025-03-27T20:12:16.400750Z","iopub.status.idle":"2025-03-27T20:12:16.407161Z","shell.execute_reply.started":"2025-03-27T20:12:16.400715Z","shell.execute_reply":"2025-03-27T20:12:16.406338Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Zip kết quả inference\n!zip -r deraining_youtube_test_output.zip \"paper_pretrained_weight_results\" \"our_fine_tuned_weight_results\"","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:12:41.173476Z","iopub.execute_input":"2025-03-27T20:12:41.173714Z","iopub.status.idle":"2025-03-27T20:12:49.277883Z","shell.execute_reply.started":"2025-03-27T20:12:41.173692Z","shell.execute_reply":"2025-03-27T20:12:49.276989Z"},"trusted":true},"outputs":[{"name":"stdout","text":"updating: paper_pretrained_weight_results/ (stored 0%)\nupdating: paper_pretrained_weight_results/results/ (stored 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/ (stored 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/ (stored 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/ (stored 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_15.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_16.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_3.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_13.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_20.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_9.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_1.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_17.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_2.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_14.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_4.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_19.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_18.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_12.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_6.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_11.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_10.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_5.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_8.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video3/frame_7.png (deflated 1%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/ (stored 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_15.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_16.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_3.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_13.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_20.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_9.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_1.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_17.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_2.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_14.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_4.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_19.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_18.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_12.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_6.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_11.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_10.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_5.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_8.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video4/frame_7.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/ (stored 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_15.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_16.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_3.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_13.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_20.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_9.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_1.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_17.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_2.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_14.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_4.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_19.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_18.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_12.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_6.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_11.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_10.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_5.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_8.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video1/frame_7.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/ (stored 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_15.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_16.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_3.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_13.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_20.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_9.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_1.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_17.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_2.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_14.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_4.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_19.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_18.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_12.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_6.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_11.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_10.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_5.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_8.png (deflated 0%)\nupdating: paper_pretrained_weight_results/results/SFNet/deraining/video2/frame_7.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/ (stored 0%)\nupdating: our_fine_tuned_weight_results/results/ (stored 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/ (stored 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/ (stored 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/ (stored 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_15.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_16.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_3.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_13.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_20.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_9.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_1.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_17.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_2.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_14.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_4.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_19.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_18.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_12.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_6.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_11.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_10.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_5.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_8.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video3/frame_7.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/ (stored 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_15.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_16.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_3.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_13.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_20.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_9.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_1.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_17.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_2.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_14.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_4.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_19.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_18.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_12.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_6.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_11.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_10.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_5.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_8.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video4/frame_7.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/ (stored 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_15.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_16.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_3.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_13.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_20.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_9.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_1.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_17.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_2.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_14.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_4.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_19.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_18.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_12.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_6.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_11.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_10.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_5.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_8.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video1/frame_7.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/ (stored 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_15.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_16.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_3.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_13.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_20.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_9.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_1.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_17.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_2.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_14.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_4.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_19.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_18.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_12.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_6.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_11.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_10.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_5.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_8.png (deflated 0%)\nupdating: our_fine_tuned_weight_results/results/SFNet/deraining/video2/frame_7.png (deflated 0%)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"%cd /kaggle/working/\n!ls","metadata":{"execution":{"iopub.status.busy":"2025-03-27T20:12:49.769613Z","iopub.execute_input":"2025-03-27T20:12:49.769955Z","iopub.status.idle":"2025-03-27T20:12:49.890061Z","shell.execute_reply.started":"2025-03-27T20:12:49.769924Z","shell.execute_reply":"2025-03-27T20:12:49.889102Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working\nderaining_youtube_test_output.zip  paper_pretrained_weight_results  test_data\nour_fine_tuned_weight_results\t   SFNet\n","output_type":"stream"}],"execution_count":47}]}